name: 'GoTest Action Report'
description: 'Generate beautiful Markdown reports from Go test output'
author: 'dipjyotimetia'
branding:
  icon: 'check-circle'
  color: 'green'

inputs:
  test-json-file:
    description: 'Path to the go test -json output file'
    required: false
    default: 'test-output.json'
  output-file:
    description: 'Path for the generated Markdown report'
    required: false
    default: 'test-report.md'
  comment-pr:
    description: 'Whether to comment the PR with the test report'
    required: false
    default: 'true'
  job-name:
    description: 'Name of the job running the tests (for multi-job reports)'
    required: false
    default: ''
  summary-only:
    description: 'Include only summary in the combined PR comment (for multi-job setups)'
    required: false
    default: 'false'
  write-summary:
    description: 'Whether to write the test report to GitHub Actions Summary'
    required: false
    default: 'false'
  create-issue-on-failure:
    description: 'Whether to create a GitHub issue when tests fail'
    required: false
    default: 'false'
  issue-title:
    description: 'Title for the GitHub issue to be created on test failure'
    required: false
    default: 'Test Failure Report'
  issue-labels:
    description: 'Comma-separated list of labels for the created issue'
    required: false
    default: 'test-failure,bug'
  issue-assignees:
    description: 'Comma-separated list of users to assign to the created issue'
    required: false
    default: ''  

runs:
  using: 'composite'
  steps:
    - name: Set up Go
      uses: actions/setup-go@v5
      with:
        go-version: '1.23'
        cache: false

    - name: Generate test report
      shell: bash
      run: |
        go run ${{ github.action_path }}/main.go -input "${{ inputs.test-json-file }}" -output "${{ inputs.output-file }}"
        
    - name: Upload Test Report
      uses: actions/upload-artifact@v4
      with:
        name: test-report${{ inputs.job-name != '' && format('_{0}', inputs.job-name) || '' }}
        path: ${{ inputs.output-file }}

    - name: Write to GitHub Actions Summary
      if: inputs.write-summary == 'true'
      shell: bash
      run: cat "${{ inputs.output-file }}" >> $GITHUB_STEP_SUMMARY

    - name: Process report for PR comment
      if: inputs.comment-pr == 'true' && github.event_name == 'pull_request'
      id: process-report
      shell: bash
      run: |
        # Add workflow run link to report
        TEMP_FILE=$(mktemp)
        sed '/Report generated at/,$d' "${{ inputs.output-file }}" > "$TEMP_FILE"
        
        echo "" >> "$TEMP_FILE"
        echo "---" >> "$TEMP_FILE"
        
        if [ -n "${{ inputs.job-name }}" ]; then
          echo "Job: **${{ inputs.job-name }}** | " >> "$TEMP_FILE"
        fi
        
        echo "[View Workflow Run](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})" >> "$TEMP_FILE"
        echo "" >> "$TEMP_FILE"
        echo "Report generated at: $(date -u +"%Y-%m-%dT%H:%M:%SZ")" >> "$TEMP_FILE"
        mv "$TEMP_FILE" "${{ inputs.output-file }}"
        
        # Process report based on settings
        if [ "${{ inputs.summary-only }}" == "true" ]; then
          # Extract only summary section
          REPORT_CONTENT=$(awk '/^## Summary$/,/^##/ {if (!/^## [^S]/) print}' "${{ inputs.output-file }}")
          
          if [ -n "${{ inputs.job-name }}" ]; then
            # Add job name header
            REPORT_CONTENT="### ${{ inputs.job-name }} Test Results\n\n${REPORT_CONTENT}"
          fi
        else
          # Use full report
          REPORT_CONTENT=$(cat "${{ inputs.output-file }}")
          
          if [ -n "${{ inputs.job-name }}" ]; then
            # Add job name header at the beginning
            TEMP_FILE=$(mktemp)
            echo "# ${{ inputs.job-name }} Test Results" > "$TEMP_FILE"
            echo "" >> "$TEMP_FILE"
            tail -n +2 "${{ inputs.output-file }}" >> "$TEMP_FILE"
            REPORT_CONTENT=$(cat "$TEMP_FILE")
          fi
        fi
        
        # Save for next steps
        echo "REPORT<<EOF" >> $GITHUB_ENV
        echo "$REPORT_CONTENT" >> $GITHUB_ENV
        echo "EOF" >> $GITHUB_ENV
        
        # Detect test status
        if grep -q "Status-FAILED-red" "${{ inputs.output-file }}"; then
          echo "TEST_STATUS=FAILED" >> $GITHUB_OUTPUT
        elif grep -q "Status-PASSED-brightgreen" "${{ inputs.output-file }}"; then
          echo "TEST_STATUS=PASSED" >> $GITHUB_OUTPUT
        else
          echo "TEST_STATUS=SKIPPED" >> $GITHUB_OUTPUT
        fi

    - name: Find existing PR comments
      if: inputs.comment-pr == 'true' && github.event_name == 'pull_request'
      uses: peter-evans/find-comment@v3
      id: find-comments
      with:
        issue-number: ${{ github.event.pull_request.number }}
        comment-author: 'github-actions[bot]'
        body-includes: "Test Summary Report"
        
    - name: Find job specific comment
      if: inputs.comment-pr == 'true' && github.event_name == 'pull_request' && inputs.job-name != ''
      uses: peter-evans/find-comment@v3
      id: find-job-comment
      with:
        issue-number: ${{ github.event.pull_request.number }}
        comment-author: 'github-actions[bot]'
        body-includes: "${{ inputs.job-name }} Test Results"

    - name: Check previous test status
      if: inputs.comment-pr == 'true' && github.event_name == 'pull_request' && steps.find-comments.outputs.comment-id != ''
      id: check-status
      shell: bash
      run: |
        if echo "${{ steps.find-comments.outputs.comment-body }}" | grep -q "Status-FAILED"; then
          echo "HAD_FAILED_TESTS=true" >> $GITHUB_ENV
          
          if [ "${{ steps.process-report.outputs.TEST_STATUS }}" == "PASSED" ]; then
            echo "NOW_PASSING=true" >> $GITHUB_ENV
            echo "STATUS_MESSAGE=ðŸŽ‰ **Previously failed tests are now passing!** ðŸŽ‰" >> $GITHUB_ENV
          else
            echo "NOW_PASSING=false" >> $GITHUB_ENV
            echo "STATUS_MESSAGE=" >> $GITHUB_ENV
          fi
        else
          echo "HAD_FAILED_TESTS=false" >> $GITHUB_ENV
          echo "NOW_PASSING=false" >> $GITHUB_ENV
          echo "STATUS_MESSAGE=" >> $GITHUB_ENV
        fi

    - name: Update individual job comment
      if: inputs.comment-pr == 'true' && github.event_name == 'pull_request' && inputs.job-name != ''
      uses: peter-evans/create-or-update-comment@v4
      with:
        issue-number: ${{ github.event.pull_request.number }}
        comment-id: ${{ steps.find-job-comment.outputs.comment-id }}
        body: |
          # ${{ inputs.job-name }} Test Results
          ${{ env.STATUS_MESSAGE }}

          ${{ env.REPORT }}
        edit-mode: replace

    - name: Update main summary comment
      if: inputs.comment-pr == 'true' && github.event_name == 'pull_request'
      uses: peter-evans/create-or-update-comment@v4
      with:
        issue-number: ${{ github.event.pull_request.number }}
        comment-id: ${{ steps.find-comments.outputs.comment-id }}
        body: |
          ${{ env.STATUS_MESSAGE }}

          ${{ env.REPORT }}
          
          <details>
          <summary>View details for all test jobs</summary>
          
          This is a combined report summary. See individual job comments for detailed reports or check the [workflow run](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}).
          </details>
        edit-mode: replace

    - name: Create issue for test failures
      if: inputs.create-issue-on-failure == 'true' && steps.process-report.outputs.TEST_STATUS == 'FAILED'
      uses: actions/github-script@v6
      with:
        github-token: ${{ github.token }}
        script: |
          const fs = require('fs');
          
          const runUrl = `https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}`;
          const issueTitle = `${{ inputs.issue-title }} - ${new Date().toISOString().split('T')[0]}`;
          const reportContent = fs.readFileSync('${{ inputs.output-file }}', 'utf8');
          
          // Create the issue body with test results
          let issueBody = `## Test Failure Report\n\n`;
          issueBody += `Test failures detected in workflow run: [View Workflow Run](${runUrl})\n\n`;
          issueBody += `### Test Report\n\n`;

          const failedTestsSection = reportContent.match(/## Test Results[\s\S]*?(?=##)/m);
          
          if (failedTestsSection) {
            issueBody += failedTestsSection[0] + "\n";
          } else {
            issueBody += "No detailed failure information available.\n";
          }
          
          // Add reference to pull request if available
          if ('${{ github.event_name }}' === 'pull_request') {
            const prNumber = '${{ github.event.pull_request.number }}';
            const prLink = `https://github.com/${{ github.repository }}/pull/${prNumber}`;
            issueBody += `\n### Related Pull Request\n\n`;
            issueBody += `This failure occurred in [PR #${prNumber}](${prLink})`;
          }
          
          issueBody += `\n\n_This issue was automatically created by the test workflow._`;
          
          // Parse labels and assignees
          const labels = '${{ inputs.issue-labels }}'.split(',').filter(l => l.trim() !== '');
          const assignees = '${{ inputs.issue-assignees }}'.split(',').filter(a => a.trim() !== '');
          
          // Create the issue
          const { data } = await github.rest.issues.create({
            owner: context.repo.owner,
            repo: context.repo.repo,
            title: issueTitle,
            body: issueBody,
            labels: labels,
            assignees: assignees
          });
          
          console.log(`Created issue #${data.number}: ${data.html_url}`);
          
          // Add the issue link to the GitHub summary
          await core.summary.addRaw(`## :warning: Test Failures Detected\n\nAn issue has been created: [#${data.number}: ${issueTitle}](${data.html_url})`).write();